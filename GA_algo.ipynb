{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NRTxNCX4OfVL"
      },
      "outputs": [],
      "source": [
        "#from MetaHeuristicsFS import FeatureSelection\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import auc,roc_auc_score,average_precision_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils import compute_class_weight\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.util import ngrams\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import random as rd\n",
        "import time\n",
        "import gc\n",
        "import pickle\n",
        "import sys\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextFeatureSelectionGA():\n",
        "    '''Use genetic algorithm for selecting text tokens which give best classification results\n",
        "    \n",
        "    Genetic Algorithm Parameters\n",
        "    ----------\n",
        "    \n",
        "    generations : Number of generations to run genetic algorithm. 500 as deafult, as used in the original paper\n",
        "    \n",
        "    population : Number of individual chromosomes. 50 as default, as used in the original paper\n",
        "    \n",
        "    prob_crossover : Probability of crossover. 0.9 as default, as used in the original paper\n",
        "    \n",
        "    prob_mutation : Probability of mutation. 0.1 as default, as used in the original paper\n",
        "    \n",
        "    percentage_of_token : Percentage of word features to be included in a given chromosome.\n",
        "        50 as default, as used in the original paper.\n",
        "    runtime_minutes : Number of minutes to run the algorithm. This is checked in between generations.\n",
        "        At start of each generation it is checked if runtime has exceeded than alloted time.\n",
        "        If case run time did exceeds provided limit, best result from generations executed so far is given as output.\n",
        "        Default is 2 hours. i.e. 120 minutes.\n",
        "        \n",
        "    References\n",
        "    ----------\n",
        "    Noria Bidi and Zakaria Elberrichi \"Feature Selection For Text Classification Using Genetic Algorithms\"\n",
        "    https://ieeexplore.ieee.org/document/7804223\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    def __init__(self,generations=20,population=50,prob_crossover=0.9,prob_mutation=0.1,percentage_of_token=50,runtime_minutes=1):\n",
        "        self.generations=generations\n",
        "        self.population=population\n",
        "        self.prob_crossover=prob_crossover\n",
        "        self.prob_mutation=prob_mutation\n",
        "        self.percentage_of_token=percentage_of_token\n",
        "        self.runtime_minutes=runtime_minutes\n",
        "        \n",
        "    def _cost_function_value(self,y_test,y_test_pred,cost_function,avrg):\n",
        "        if cost_function == 'f1':\n",
        "            if avrg == 'binary':\n",
        "                metric=f1_score(y_test,y_test_pred,average='binary')\n",
        "\n",
        "        elif cost_function == 'precision':\n",
        "            if avrg == 'binary':\n",
        "                metric=precision_score(y_test,y_test_pred,average='binary')\n",
        "\n",
        "        elif cost_function == 'recall':\n",
        "            if avrg == 'binary':\n",
        "                metric=recall_score(y_test,y_test_pred,average='binary')\n",
        "        elif cost_function == 'accuracy':\n",
        "                metric=accuracy_score(y_test,y_test_pred)\n",
        "\n",
        "        return metric\n",
        "\n",
        "\n",
        "    def _computeFitness(self,gene,unique_words,x,y,model,model_metric,avrg,analyzer,min_df,max_df,stop_words,tokenizer,token_pattern,lowercase):\n",
        "        ### create tfidf matrix for only terms which are in gene\n",
        "        # get terms from gene and vocabulary combnation\n",
        "        term_to_use=list(np.array(unique_words)[list(map(bool,gene))])\n",
        "\n",
        "        metric_result=[]\n",
        "        skfold=StratifiedKFold(n_splits=5)\n",
        "\n",
        "        ##get words based on gene index to get vocabulary\n",
        "        term_to_use=list(np.array(unique_words)[list(map(bool,gene))])\n",
        "\n",
        "        for train_index, test_index in skfold.split(x,y):\n",
        "            #get x_train,y_train  x_test,y_test\n",
        "            X_train, X_test = list(np.array(x)[train_index]),list(np.array(x)[test_index]) \n",
        "            y_train, y_test = np.array(y)[train_index],np.array(y)[test_index]\n",
        "\n",
        "            ##based on vocabulary set, create tfidf matrix for train and test data\n",
        "            tfidf=TfidfVectorizer(vocabulary=term_to_use,analyzer=analyzer,min_df=min_df,max_df=max_df,stop_words=stop_words,tokenizer=tokenizer,token_pattern=token_pattern,lowercase=lowercase)\n",
        "            tfidfvec_vectorizer=tfidf.fit(X_train)\n",
        "\n",
        "            #get x train and test\n",
        "            X_train=tfidfvec_vectorizer.transform(X_train)\n",
        "            X_test=tfidfvec_vectorizer.transform(X_test)\n",
        "\n",
        "            #train model\n",
        "            model.fit(X_train,y_train)\n",
        "\n",
        "            #predict probability for test\n",
        "            y_test_pred=model.predict(X_test)\n",
        "\n",
        "            #get desired metric and append to metric_result\n",
        "            metric_result.append(self._cost_function_value(y_test,y_test_pred,model_metric,avrg))\n",
        "\n",
        "        return np.mean(metric_result)\n",
        "\n",
        "\n",
        "\n",
        "    def _check_unmatchedrows(self,population_matrix,population_array):\n",
        "        pop_check=0\n",
        "        #in each row of population matrix\n",
        "        for pop_so_far in range(population_matrix.shape[0]):\n",
        "            #check if it is duplicate\n",
        "            if sum(population_matrix[pop_so_far]!=population_array)==population_array.shape[0]:\n",
        "                #assign 1 as value if it is duplicate and break loop\n",
        "                pop_check=1\n",
        "                break\n",
        "\n",
        "        return pop_check\n",
        "\n",
        "    def _get_population(self,population,population_matrix,population_array):\n",
        "        iterate=0\n",
        "        ##append until population and no duplicate chromosome\n",
        "        while population_matrix.shape[0] < population:\n",
        "            ##prepare population matrix\n",
        "            rd.shuffle(population_array)\n",
        "            #check if it is first iteration, if yes append\n",
        "            if iterate==0:\n",
        "                population_matrix = np.vstack((population_matrix,population_array))\n",
        "                iterate+=1\n",
        "            #if second iteration and one chromosome already, check if it is duplicate\n",
        "            elif iterate==1 and sum(population_matrix[0]==population_array)!=population_array.shape[0]:\n",
        "                population_matrix = np.vstack((population_matrix,population_array))\n",
        "                iterate+=1\n",
        "            #when iteration second and beyond check duplicacy\n",
        "            elif iterate>1:# and self._check_unmatchedrows(population_matrix,population_array)==0:\n",
        "                population_matrix = np.vstack((population_matrix,population_array))\n",
        "                iterate+=1\n",
        "\n",
        "        return population_matrix\n",
        "\n",
        "\n",
        "    def _get_parents(self,population_array,population_matrix,unique_words,x,y,model,model_metric,avrg,analyzer,min_df,max_df,stop_words,tokenizer,token_pattern,lowercase):\n",
        "\n",
        "        #keep space for best chromosome\n",
        "        parents = np.empty((0,population_array.shape[0]))\n",
        "\n",
        "        #get 6 unique index to fetch from population\n",
        "        indexes=np.random.randint(0,population_matrix.shape[0],6)\n",
        "        while len(np.unique(indexes))<6:\n",
        "            indexes=np.random.randint(0,len(population_matrix),6)\n",
        "\n",
        "        #mandatory run twice as per GA algorithm\n",
        "        for run_range in range(2):\n",
        "            #get 3 unique index to fetch from population\n",
        "            #if first run then until half\n",
        "            if run_range==0:\n",
        "                index_run=indexes[0:3]\n",
        "            #if second run then from half till end\n",
        "            else:\n",
        "                index_run=indexes[3:]\n",
        "\n",
        "            ##gene pool 1\n",
        "            gene_1 = population_matrix[index_run[0]]\n",
        "            #cost of gene 1\n",
        "            cost1=self._computeFitness(gene=gene_1,unique_words=unique_words,x=x,y=y,model=model,model_metric=model_metric,avrg=avrg,analyzer=analyzer,min_df=min_df,max_df=max_df,stop_words=stop_words,tokenizer=tokenizer,token_pattern=token_pattern,lowercase=lowercase)\n",
        "            ##gene pool 2\n",
        "            gene_2 = population_matrix[index_run[1]]\n",
        "            #cost of gene 2\n",
        "            cost2=self._computeFitness(gene=gene_2,unique_words=unique_words,x=x,y=y,model=model,model_metric=model_metric,avrg=avrg,analyzer=analyzer,min_df=min_df,max_df=max_df,stop_words=stop_words,tokenizer=tokenizer,token_pattern=token_pattern,lowercase=lowercase)\n",
        "            ##gene pool 3\n",
        "            gene_3 = population_matrix[index_run[2]]\n",
        "            #cost of gene 3\n",
        "            cost3=self._computeFitness(gene=gene_3,unique_words=unique_words,x=x,y=y,model=model,model_metric=model_metric,avrg=avrg,analyzer=analyzer,min_df=min_df,max_df=max_df,stop_words=stop_words,tokenizer=tokenizer,token_pattern=token_pattern,lowercase=lowercase)\n",
        "\n",
        "            #get best chromosome from 3 and assign best chromosome.\n",
        "            if cost1==max(cost1,cost2,cost3):\n",
        "                parents = np.vstack((parents,gene_1))\n",
        "            elif cost2==max(cost1,cost2,cost3):\n",
        "                parents = np.vstack((parents,gene_2))\n",
        "            elif cost3==max(cost1,cost2,cost3):\n",
        "                parents = np.vstack((parents,gene_3))\n",
        "\n",
        "        #get 2 best chromosome identified as parents\n",
        "        return parents[0],parents[1]\n",
        "\n",
        "    def _crossover(self,parent1,parent2,prob_crossover):\n",
        "\n",
        "        #placeholder for child chromosome\n",
        "        child1 = np.empty((0,len(parent1)))\n",
        "        child2 = np.empty((0,len(parent2)))\n",
        "\n",
        "        #generate random number ofr crossover probability\n",
        "        crsvr_rand_prob = np.random.rand()\n",
        "\n",
        "        ## if random decimal generated is less than probability of crossover set\n",
        "        if crsvr_rand_prob < prob_crossover:\n",
        "            index1 = np.random.randint(0,len(parent1))\n",
        "            index2 = np.random.randint(0,len(parent1))\n",
        "\n",
        "            # get different indices\n",
        "            # to make sure you will crossover at least one gene\n",
        "            while index1 == index2:\n",
        "                index2 = np.random.randint(0,len(parent1))\n",
        "\n",
        "            index_parent1 = min(index1,index2) \n",
        "            index_parent2 = max(index1,index2) \n",
        "\n",
        "            ## Parent 1\n",
        "            # first segment\n",
        "            first_seg_parent1 = parent1[:index_parent1]\n",
        "            # middle segment; where the crossover will happen\n",
        "            mid_seg_parent1 = parent1[index_parent1:index_parent2+1]\n",
        "            # last segment\n",
        "            last_seg_parent1 = parent1[index_parent2+1:]\n",
        "            ## child from all segments\n",
        "            child1 = np.concatenate((first_seg_parent1,mid_seg_parent1,last_seg_parent1))                \n",
        "\n",
        "            ### Parent 2\n",
        "            # first segment\n",
        "            first_seg_parent2 = parent2[:index_parent2]\n",
        "            # middle segment; where the crossover will happen\n",
        "            mid_seg_parent2 = parent2[index_parent2:index_parent2+1]\n",
        "            # last segment\n",
        "            last_seg_parent2 = parent2[index_parent2+1:]\n",
        "            ## child from all segments\n",
        "            child2 = np.concatenate((first_seg_parent2,mid_seg_parent2,last_seg_parent2))        \n",
        "            return child1,child2\n",
        "        #if probability logic is bypassed\n",
        "        else:\n",
        "            return parent1,parent2\n",
        "\n",
        "    def _mutation(self,child,prob_mutation):\n",
        "\n",
        "        # mutated child 1 placeholder\n",
        "        mutated_child = np.empty((0,len(child)))\n",
        "\n",
        "        ## get random probability at each index of chromosome and start with 0    \n",
        "        t = 0\n",
        "        for cld1 in child:\n",
        "            rand_prob_mutation = np.random.rand() # do we mutate or no???\n",
        "            # if random decimal generated is less than random probability, then swap value at index position\n",
        "            if rand_prob_mutation < prob_mutation:\n",
        "                # swap value\n",
        "                if child[t] == 0:\n",
        "                    child[t] = 1            \n",
        "                else:\n",
        "                    child[t] = 0\n",
        "                # assign temporary child chromosome\n",
        "                mutated_child = child\n",
        "\n",
        "            #if random prob is >= mutation probability, assign as it is\n",
        "            else:\n",
        "                mutated_child = child\n",
        "\n",
        "            # increase counter\n",
        "            t = t+1\n",
        "        return mutated_child\n",
        "    \n",
        "    def _getPopulationAndMatrix(self,doc_list,label_list,analyzer,min_df,max_df,stop_words,tokenizer,token_pattern,lowercase):\n",
        "        #get null free df\n",
        "        temp_df=pd.DataFrame({'doc_list':doc_list,'label_list':label_list})\n",
        "        temp_df=temp_df[(~temp_df['doc_list'].isna()) & (~temp_df['label_list'].isna())]\n",
        "        temp_df.reset_index(inplace=True,drop=True)\n",
        "        label_list=temp_df['label_list'].tolist()\n",
        "        doc_list=temp_df['doc_list'].tolist()\n",
        "        del temp_df\n",
        "        gc.collect()\n",
        "\n",
        "        #get unique tokens\n",
        "        tfidfvec = TfidfVectorizer(analyzer=analyzer,min_df=min_df,max_df=max_df,stop_words=stop_words,tokenizer=tokenizer,token_pattern=token_pattern,lowercase=lowercase)\n",
        "        tfidfvec_vectorizer = tfidfvec.fit(doc_list)\n",
        "        unique_words=list(tfidfvec_vectorizer.vocabulary_.keys())\n",
        "\n",
        "        #count of tokens to consider based on percentage\n",
        "        chromosome_to_feature = int(round((len(unique_words)/100)*self.percentage_of_token))\n",
        "\n",
        "        #generate chromosome with number of 1 equal to percentage from total features specified by user\n",
        "        population_array=np.concatenate([np.zeros(len(unique_words)-chromosome_to_feature),np.ones(chromosome_to_feature)])\n",
        "        #shuffle after concatenating 0 and 1\n",
        "        rd.shuffle(population_array)\n",
        "\n",
        "        #create blank population matrix to append all individual chromosomes. number of rows equal to population size\n",
        "        population_matrix = np.empty((0,len(unique_words)))\n",
        "\n",
        "        #get population matrix\n",
        "        population_matrix=self._get_population(self.population,population_matrix,population_array)\n",
        "\n",
        "        #best solution for each generation\n",
        "        best_of_a_generation = np.empty((0,len(population_array)+1))\n",
        "        \n",
        "        return doc_list,label_list,unique_words,population_array,population_matrix,best_of_a_generation\n",
        "\n",
        "    def getGeneticFeatures(self,doc_list,label_list,model=LogisticRegression(),model_metric='accuracy',avrg='binary',analyzer='word',min_df=2,max_df=1.0,stop_words=None,tokenizer=None,token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',lowercase=True):\n",
        "        '''\n",
        "        Data Parameters\n",
        "        ----------        \n",
        "        doc_list : text documents in a python list. \n",
        "            Example: ['i had dinner','i am on vacation','I am happy','Wastage of time']\n",
        "        \n",
        "        label_list : labels in a python list.\n",
        "            Example: ['Neutral','Neutral','Positive','Negative']\n",
        "        \n",
        "        \n",
        "        Modelling Parameters\n",
        "        ----------\n",
        "        model : Set a model which has .fit function to train model and .predict function to predict for test data. \n",
        "            This model should also be able to train classifier using TfidfVectorizer feature.\n",
        "            Default is set as Logistic regression in sklearn\n",
        "        \n",
        "        model_metric : Classifier cost function. Select one from: ['f1','precision','recall'].\n",
        "            Default is F1\n",
        "        \n",
        "        avrg : Averaging used in model_metric. Select one from ['micro', 'macro', 'samples','weighted', 'binary'].\n",
        "            For binary classification, default is 'binary' and for multi-class classification, default is 'micro'.\n",
        "        \n",
        "        \n",
        "        TfidfVectorizer Parameters\n",
        "        ----------\n",
        "        analyzer : {'word', 'char', 'char_wb'} or callable, default='word'\n",
        "            Whether the feature should be made of word or character n-grams.\n",
        "            Option 'char_wb' creates character n-grams only from text inside\n",
        "            word boundaries; n-grams at the edges of words are padded with space.\n",
        "            \n",
        "        min_df : float or int, default=2\n",
        "            When building the vocabulary ignore terms that have a document\n",
        "            frequency strictly lower than the given threshold. This value is also\n",
        "            called cut-off in the literature.\n",
        "            If float in range of [0.0, 1.0], the parameter represents a proportion\n",
        "            of documents, integer absolute counts.\n",
        "            This parameter is ignored if vocabulary is not None.\n",
        "        max_df : float or int, default=1.0\n",
        "            When building the vocabulary ignore terms that have a document\n",
        "            frequency strictly higher than the given threshold (corpus-specific\n",
        "            stop words).\n",
        "            If float in range [0.0, 1.0], the parameter represents a proportion of\n",
        "            documents, integer absolute counts.\n",
        "            This parameter is ignored if vocabulary is not None.\n",
        "        stop_words : {'english'}, list, default=None\n",
        "            If a string, it is passed to _check_stop_list and the appropriate stop\n",
        "            list is returned. 'english' is currently the only supported string\n",
        "            value.\n",
        "            There are several known issues with 'english' and you should\n",
        "            consider an alternative (see :ref:`stop_words`).\n",
        "            If a list, that list is assumed to contain stop words, all of which\n",
        "            will be removed from the resulting tokens.\n",
        "            Only applies if ``analyzer == 'word'``.\n",
        "            If None, no stop words will be used. max_df can be set to a value\n",
        "            in the range [0.7, 1.0) to automatically detect and filter stop\n",
        "            words based on intra corpus document frequency of terms.\n",
        "        tokenizer : callable, default=None\n",
        "            Override the string tokenization step while preserving the\n",
        "            preprocessing and n-grams generation steps.\n",
        "            Only applies if ``analyzer == 'word'``\n",
        "        token_pattern : str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n",
        "            Regular expression denoting what constitutes a \"token\", only used\n",
        "            if ``analyzer == 'word'``. The default regexp selects tokens of 2\n",
        "            or more alphanumeric characters (punctuation is completely ignored\n",
        "            and always treated as a token separator).\n",
        "            If there is a capturing group in token_pattern then the\n",
        "            captured group content, not the entire match, becomes the token.\n",
        "            At most one capturing group is permitted.\n",
        "        lowercase : bool, default=True\n",
        "            Convert all characters to lowercase before tokenizing.        \n",
        "        '''\n",
        "        \n",
        "        start = time.time()\n",
        "        \n",
        "        #define cost function averaging\n",
        "        if len(set(label_list))>2:\n",
        "            avrg='micro'\n",
        "        else:\n",
        "            avrg='binary'\n",
        "        \n",
        "        #get all parameters needed for GA\n",
        "        doc_list,label_list,unique_words,population_array,population_matrix,best_of_a_generation=self._getPopulationAndMatrix(doc_list,label_list,analyzer=analyzer,min_df=min_df,max_df=max_df,stop_words=stop_words,tokenizer=tokenizer,token_pattern=token_pattern,lowercase=lowercase)\n",
        "        \n",
        "        #Execute GA\n",
        "        for genrtn in range(self.generations):\n",
        "            \n",
        "            ##if time exceeds then break loop\n",
        "            if (time.time()-start)//60 > self.runtime_minutes:\n",
        "                print('Run time exceeded allocated time. Producing best features generated so far:')\n",
        "                break\n",
        "            \n",
        "            # placeholder for saving the new generation\n",
        "            new_population = np.empty((0,len(population_array)))\n",
        "\n",
        "            # placeholder for saving the new generation and obj func val\n",
        "            new_population_with_obj_val = np.empty((0,len(population_array)+1))\n",
        "\n",
        "            # placeholder for saving the best solution for each generation\n",
        "            sorted_best = np.empty((0,len(population_array)+1))\n",
        "\n",
        "            ## generate new set of population in each generation\n",
        "            # each iteration gives 2 chromosome.\n",
        "            # Doing it half the population size will mean getting matrix of population size equal to original matrix\n",
        "            for family in range(int(self.population/2)):\n",
        "                #get parents\n",
        "                parent1,parent2=self._get_parents(population_array=population_array,population_matrix=population_matrix,unique_words=unique_words,x=doc_list,y=label_list,model=model,model_metric=model_metric,avrg=avrg,analyzer=analyzer,min_df=min_df,max_df=max_df,stop_words=stop_words,tokenizer=tokenizer,token_pattern=token_pattern,lowercase=lowercase)\n",
        "\n",
        "                #crossover\n",
        "                child1,child2=self._crossover(parent1=parent1,parent2=parent2,prob_crossover=self.prob_crossover)\n",
        "\n",
        "                #mutation\n",
        "                mutated_child1=self._mutation(child=child1,prob_mutation=self.prob_mutation)\n",
        "                mutated_child2=self._mutation(child=child2,prob_mutation=self.prob_mutation)\n",
        "\n",
        "                #get cost function for 2 mutated child and print for generation, family and child\n",
        "                cost1=self._computeFitness(gene=mutated_child1,unique_words=unique_words,x=doc_list,y=label_list,model=model,model_metric=model_metric,avrg=avrg,analyzer=analyzer,min_df=min_df,max_df=max_df,stop_words=stop_words,tokenizer=tokenizer,token_pattern=token_pattern,lowercase=lowercase)\n",
        "                cost2=self._computeFitness(gene=mutated_child2,unique_words=unique_words,x=doc_list,y=label_list,model=model,model_metric=model_metric,avrg=avrg,analyzer=analyzer,min_df=min_df,max_df=max_df,stop_words=stop_words,tokenizer=tokenizer,token_pattern=token_pattern,lowercase=lowercase)\n",
        "\n",
        "                #create population for next generaion\n",
        "                new_population = np.vstack((new_population,mutated_child1,mutated_child2))\n",
        "\n",
        "                #save cost and child\n",
        "                mutant1_with_obj_val = np.hstack((cost1,mutated_child1))\n",
        "                mutant2_with_obj_val = np.hstack((cost2,mutated_child2))\n",
        "                #stack both chromosome of the family\n",
        "                new_population_with_obj_val = np.vstack((new_population_with_obj_val,mutant1_with_obj_val,mutant2_with_obj_val))\n",
        "\n",
        "            #at end of the generation, change population as the stacked chromosome set from previous generation\n",
        "            population_matrix=new_population\n",
        "\n",
        "            ### find best solution for generation based on objective function and stack\n",
        "            sorted_best = np.array(sorted(new_population_with_obj_val,key=lambda x:x[0],reverse=True))\n",
        "\n",
        "            # print and stack\n",
        "            print('Generation:',genrtn,'best score',sorted_best[0][0])\n",
        "            best_of_a_generation = np.vstack((best_of_a_generation,sorted_best[0]))\n",
        "\n",
        "        #sort by metric\n",
        "        best_metric_chromosome_pair = np.array(sorted(best_of_a_generation,key=lambda x:x[0],reverse=True))[0]\n",
        "\n",
        "        #best chromosome, metric and vocabulary\n",
        "        best_chromosome=best_metric_chromosome_pair[1:]\n",
        "\n",
        "        best_metric=best_metric_chromosome_pair[0]\n",
        "        print('Best metric:',best_metric)\n",
        "\n",
        "        best_vocabulary=list(np.array(unique_words)[list(map(bool,best_chromosome))])\n",
        "        return best_vocabulary   "
      ],
      "metadata": {
        "id": "SnTBMFuVOf95"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0SY0g6CCSap4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data=pd.read_excel(\"/content/drive/MyDrive/AI/eval.xlsx\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "d_xh0DCUu_iN",
        "outputId": "3e9c2e24-ed83-420a-d70d-5a389c163a05"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  HS\n",
              "0     Hurray, saving us $$$ in so many ways @potus @...   1\n",
              "1     Why would young fighting age men be the vast m...   1\n",
              "2     @KamalaHarris Illegals Dump their Kids at the ...   1\n",
              "3     NY Times: 'Nearly All White' States Pose 'an A...   0\n",
              "4     Orban in Brussels: European leaders are ignori...   0\n",
              "...                                                 ...  ..\n",
              "8995  @mmdwriter @JRubinBlogger @BenSasse I am proud...   0\n",
              "8996  @CheriJacobus Hollywood is complicit in the ra...   0\n",
              "8997  @amaziah_filani What a fucking cunt I hate see...   1\n",
              "8998                  Hysterical woman like @CoryBooker   0\n",
              "8999  Nearly every woman I know has #meToo in their ...   0\n",
              "\n",
              "[9000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b09fa95-d81c-47b2-88ad-066e714c14e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>HS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why would young fighting age men be the vast m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>@mmdwriter @JRubinBlogger @BenSasse I am proud...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>@CheriJacobus Hollywood is complicit in the ra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>@amaziah_filani What a fucking cunt I hate see...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>Hysterical woman like @CoryBooker</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>Nearly every woman I know has #meToo in their ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b09fa95-d81c-47b2-88ad-066e714c14e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b09fa95-d81c-47b2-88ad-066e714c14e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b09fa95-d81c-47b2-88ad-066e714c14e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_list=data['text']\n",
        "label_list=data['HS']\n",
        "label_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjrHJVnIwdUp",
        "outputId": "3e4c5783-da12-4e78-b973-f18a042da22c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "8995    0\n",
              "8996    0\n",
              "8997    1\n",
              "8998    0\n",
              "8999    0\n",
              "Name: HS, Length: 9000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(label_list)):\n",
        "     if label_list[i]==1:\n",
        "         label_list[i] = 'pos'\n",
        "     else:\n",
        "         label_list[i] = 'neg'\n",
        "label_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpk7gpwMxEnO",
        "outputId": "8ad26566-2fdb-4bed-a20f-6ee5a023c05f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-03a94018f980>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  label_list[i] = 'pos'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       pos\n",
              "1       pos\n",
              "2       pos\n",
              "3       neg\n",
              "4       neg\n",
              "       ... \n",
              "8995    neg\n",
              "8996    neg\n",
              "8997    pos\n",
              "8998    neg\n",
              "8999    neg\n",
              "Name: HS, Length: 9000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getGAobj=TextFeatureSelectionGA(percentage_of_token=60)\n",
        "best_vocabulary=getGAobj.getGeneticFeatures(doc_list=doc_list,label_list=label_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODb0kg4sP94H",
        "outputId": "2bc30c74-d784-4cbd-abd6-c3425ccc1c91"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation: 0 best score 0.7385555555555555\n",
            "Run time exceeded allocated time. Producing best features generated so far:\n",
            "Best metric: 0.7385555555555555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvDWRyp5WjpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}